{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a48f91d0",
   "metadata": {},
   "source": [
    "# CLASE 5.2: MANIPULACIÓN DE DATOS EN ESTRUCTURAS DE **<font color=\"mediumorchid\">POLARS</font>**.\n",
    "---\n",
    "\n",
    "## Carga y guardado de datos en **<font color=\"mediumorchid\">Polars</font>**.\n",
    "Como ya hemos visto en todo el desarrollo de la asignatura, en general, el acceso a la información de interés propia de algún fenómeno, proceso o sistema que estamos interesados en analizar, suele provenir de archivos externos, muchas veces preprocesados por terceros. Por lo tanto, es común que hagamos uso de funciones especializadas en leer y/o acceder a tales archivos, o bien, que guarden las series y/o DataFrames que construyamos como resultado de algún análisis en nuestro computador. En **<font color=\"mediumorchid\">Polars</font>**, tales funciones se resumen en un conjunto conocido como **IO** (del inglés **Input/Output**).\n",
    "\n",
    "Antes de comentar las funciones de IO propias de **<font color=\"mediumorchid\">Polars</font>**, importaremos esta librería (junto con **<font color=\"mediumorchid\">Numpy</font>** y **<font color=\"mediumorchid\">Pandas</font>**) a fin de hacer las correspondientes comparaciones en tiempo de ejecución que, en esta sección, sí serán de enorme importancia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b1006ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b58a5d4",
   "metadata": {},
   "source": [
    "En esta sección, haremos uso de algunos archivos ubicados en la carpeta `datasets`, a fin de ejemplificar en primera instancia el cómo acceder a la data contenida en los mismos mediante el uso de algunas funciones de IO en **<font color=\"mediumorchid\">Polars</font>**. Partiremos, como en el caso de **<font color=\"mediumorchid\">Pandas</font>**, mostrando el acceso a archivos nativos de Microsoft Excel, a los que podremos acceder siempre por medio de la función `pl.read_excel()`. Sin embargo, para ello, será necesario instalar un motor de lectura de archivos de este tipo distinto del usado en **<font color=\"mediumorchid\">Pandas</font>**, llamado `xlsx2csv`. Para ello, mediante nuestra consola, escribimos la instrucción:\n",
    "\n",
    "    pip install xlsx2csv\n",
    "\n",
    "Y ya podemos acceder a nuestros archivos de Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad01cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceso a un archivo nativo de Excel en Polars.\n",
    "data = pl.read_excel(source=\"datasets/pillars_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82712ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌────────────┬────────────┬──────┬──────────┬────────────────┬───────────┬─────────────┐\n",
      "│ x          ┆ y          ┆ z    ┆ area     ┆ frec_fracturas ┆ sigma_z   ┆ tiraje_prom │\n",
      "│ ---        ┆ ---        ┆ ---  ┆ ---      ┆ ---            ┆ ---       ┆ ---         │\n",
      "│ f64        ┆ f64        ┆ i64  ┆ f64      ┆ f64            ┆ f64       ┆ f64         │\n",
      "╞════════════╪════════════╪══════╪══════════╪════════════════╪═══════════╪═════════════╡\n",
      "│ 776.718035 ┆ 259.185135 ┆ 1125 ┆ 286.5643 ┆ 1.979          ┆ 11.126392 ┆ 122.685     │\n",
      "│ 811.143435 ┆ 263.059235 ┆ 1125 ┆ 286.5643 ┆ 3.07           ┆ 9.646313  ┆ 121.178     │\n",
      "│ 845.568835 ┆ 266.933335 ┆ 1125 ┆ 286.5643 ┆ 3.07           ┆ 10.590594 ┆ 118.942     │\n",
      "│ 879.994235 ┆ 270.807435 ┆ 1125 ┆ 286.5643 ┆ 1.75           ┆ 10.605144 ┆ 120.012     │\n",
      "│ 914.419635 ┆ 274.681535 ┆ 1125 ┆ 286.5643 ┆ 0.67           ┆ 10.059537 ┆ 122.787     │\n",
      "└────────────┴────────────┴──────┴──────────┴────────────────┴───────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Mostramos las primeras 5 filas de este DataFrame.\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98392387",
   "metadata": {},
   "source": [
    "Como en el caso de **<font color=\"mediumorchid\">Pandas</font>**, el acceso a archivos nativos y/o creados por Microsoft Excel en **<font color=\"mediumorchid\">Polars</font>** es una tarea que consume varios recursos de memoria, y puede catalogarse como de ejecución *lenta*. Sin embargo, **<font color=\"mediumorchid\">Polars</font>** es capaz de acceder a estos archivos más rápido que **<font color=\"mediumorchid\">Pandas</font>**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "598b39c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.4 ms ± 3.41 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "31.9 ms ± 3.05 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pd.read_excel(io=\"datasets/pillars_data.xlsx\")\n",
    "%timeit pl.read_excel(source=\"datasets/pillars_data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b94ea58",
   "metadata": {},
   "source": [
    "Es posible seleccionar cualquier hoja en un libro de Excel accediendo al archivo mediante la función `pl.read_excel()`, usando el parámetro `sheet_name` para especificar el nombre de la hoja de interés. Podemos, igualmente, guardar cualquier DataFrame de interés en este formato en **<font color=\"mediumorchid\">Polars</font>**, haciendo uso del método `write_excel()`, especificando la ruta y el nombre del archivo resultante mediante el parámetro `workbook`. Sin embargo, para ello, necesitamos instalar primero la librería `xlsxwriter`, a fin de dotar a **<font color=\"mediumorchid\">Polars</font>** con la capacidad de crear este tipo de archivos:\n",
    "\n",
    "    pip install XlsxWriter\n",
    "\n",
    "Y ahora sí ya estamos en condiciones de almacenar nuestro DataFrame en un formato de libro de Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18684f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xlsxwriter.workbook.Workbook at 0x7fa0211e69d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Almacenamos el DataFrame en un formato de Excel (con un nombre diferente).\n",
    "data.write_excel(workbook=\"datasets/pillars_data_copy.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea58b771",
   "metadata": {},
   "source": [
    "Por supuesto, existen otros formatos de archivos a los cuales podemos acceder por medio de **<font color=\"mediumorchid\">Polars</font>**. Una opción muy popular, conforme lo visto en **<font color=\"mediumorchid\">Pandas</font>**, corresponde a los archivos `csv`, los cuales pueden cargarse fácilmente por medio de la función `pl_read_csv()`, especificando la ruta y/o nombre del archivo de interés por medio del parámetro `source`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4881f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos un archivo csv por medio de Polars.\n",
    "data = pl.read_csv(source=\"datasets/pillars_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c04c7fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌────────────┬────────────┬──────┬──────────┬────────────────┬───────────┬─────────────┐\n",
      "│ x          ┆ y          ┆ z    ┆ area     ┆ frec_fracturas ┆ sigma_z   ┆ tiraje_prom │\n",
      "│ ---        ┆ ---        ┆ ---  ┆ ---      ┆ ---            ┆ ---       ┆ ---         │\n",
      "│ f64        ┆ f64        ┆ i64  ┆ f64      ┆ f64            ┆ f64       ┆ f64         │\n",
      "╞════════════╪════════════╪══════╪══════════╪════════════════╪═══════════╪═════════════╡\n",
      "│ 776.718035 ┆ 259.185135 ┆ 1125 ┆ 286.5643 ┆ 1.979          ┆ 11.126392 ┆ 122.685     │\n",
      "│ 811.143435 ┆ 263.059235 ┆ 1125 ┆ 286.5643 ┆ 3.07           ┆ 9.646313  ┆ 121.178     │\n",
      "│ 845.568835 ┆ 266.933335 ┆ 1125 ┆ 286.5643 ┆ 3.07           ┆ 10.590594 ┆ 118.942     │\n",
      "│ 879.994235 ┆ 270.807435 ┆ 1125 ┆ 286.5643 ┆ 1.75           ┆ 10.605144 ┆ 120.012     │\n",
      "│ 914.419635 ┆ 274.681535 ┆ 1125 ┆ 286.5643 ┆ 0.67           ┆ 10.059537 ┆ 122.787     │\n",
      "└────────────┴────────────┴──────┴──────────┴────────────────┴───────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Mostramos las primeras 5 filas de este DataFrame.\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a015e1",
   "metadata": {},
   "source": [
    "El archivo cuya data hemos cargado corresponde a una tabla que muestra algunos parámetros de interés relativos a unos pilares del nivel de producción de una mina explotada mediante el método Panel Caving. Las columnas que definen a esta tabla (y que se muestran en el DataFrame) son las siguientes:\n",
    "\n",
    "- `x`: Coordenada X (en metros) del pilar en el sistema de referencia de la mina.\n",
    "- `y`: Coordenada Y (en metros) del pilar en el sistema de referencia de la mina.\n",
    "- `z`: Coordenada Z (en metros) del pilar en el sistema de referencia de la mina.\n",
    "- `area`: Área del pilar (en metros cuadrados).\n",
    "- `frec_fracturas`: Frecuencia de fracturas asociada al pilar (en número de fracturas por metro lineal), y que corresponde a una estimación de la calidad geotécnica del macizo rocoso que constituye cada pilar.\n",
    "- `sigma_z`: Carga vertical pre-minería (en MPa) estimada sobre el pilar mediante modelamiento numérico de esfuerzos.\n",
    "- `tiraje_prom`: Tonelaje promedio de mineral extraído desde los puntos de extracción inmediatamente adyacentes a cada pilar.\n",
    "\n",
    "Como en el caso de la carga directa de datos desde archivos de Excel, **<font color=\"mediumorchid\">Polars</font>**, suele ser mucho más rápido que **<font color=\"mediumorchid\">Pandas</font>** al cargar archivos de tipo `csv`. Para el caso de nuestro archivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cc49b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8 ms ± 184 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "413 µs ± 7.34 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pd.read_csv(filepath_or_buffer=\"datasets/pillars_data.csv\")\n",
    "%timeit pl.read_csv(source=\"datasets/pillars_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d823b",
   "metadata": {},
   "source": [
    "Vemos pues que **<font color=\"mediumorchid\">Polars</font>** carga el mismo archivo `csv`, aproximadamente, cuatro veces más rápido que **<font color=\"mediumorchid\">Pandas</font>**.\n",
    "\n",
    "Existen varios parámetros de interés que podemos manipular en la función `pl.read_csv()`. Algunos que puntualmente resultan muy importantes son:\n",
    "\n",
    "- `try_parse_dates`: Parámetro Booleano que permite dejar que **<font color=\"mediumorchid\">Polars</font>** intente especificar datos que podrían representar fechas, transformando tales datos en un formato adecuado a dichas fechas (siempre que corresponda). \n",
    "- `null_values`: Parámetro que permite especificar uno o más valores (normalmente strings) en una lista que serán intepreetados por **<font color=\"mediumorchid\">Polars</font>** como datos de tipo `nan`. Se trata de un parámetro especialmente útil cuando descargamos datos directamente desde sensores, ya que, si conocemos los códigos de error, podemos usarlos para que **<font color=\"mediumorchid\">Polars</font>** automáticamente los interprete como datos nulos y, de esa manera, el tipo de dato asociado a una determinada columna no se vea distorsionado. En **<font color=\"mediumorchid\">Pandas</font>** existe un parámetro que hace exactamente lo mismo para el caso de la función `pd.read_csv()`, llamado `na_values`.\n",
    "- `separator`: Parámetro que permite especificar el caracter que actúa como delimitador de cada columna en el archivo. En archivos de tipo `csv`, dicho separador suele ser una coma (que corresponde al parámetro por defecto, y que se especifica como `\",\"`), pero puede haber casos en los cuales el separador es un punto y coma (`\";\"`), u otros caracteres que podemos revisar en la correspondiente [documentación](https://pola-rs.github.io/polars/py-polars/html/reference/api/polars.read_csv.html).\n",
    "\n",
    "**<font color=\"mediumorchid\">Polars</font>** igualmente nos permite guardar cualquier serie o DataFrame en nuestro computador en formato `csv`, haciendo uso del método `write_csv()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4acaa608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado de nuestro DataFrame en formato csv.\n",
    "data.write_csv(file=\"datasets/pillars_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d3cbfd",
   "metadata": {},
   "source": [
    "**<font color=\"mediumorchid\">Polars</font>** también nos permite **escanear** cualquier archivo `csv` y guardarlo en una estructura de datos (u objeto) llamada `LazyFrame`. Tal estructura es muy parecida a un DataFrame, con la **enorme** diferencia de que un LazyFrame no dispondrá de ningún agregado visual que nos permita gastar recursos en imprimirlo, mostrarlo o *jugar* con él. Vale decir, se trata de un objeto donde *sabemos* que están nuestros datos, pero que no mostraremos (ni dejaremos que **<font color=\"mediumorchid\">Polars</font>** lo vea) a no ser que *nosotros* lo deseemos.\n",
    "\n",
    "El escaneo de un archivo `csv` puede realizarse por medio de la función `pl_scan_csv()`, y que tiene casi los mismos parámetros que `pl.read_csv()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "392427f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.scan_csv(source=\"datasets/pillars_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0100c833",
   "metadata": {},
   "source": [
    "La variable `df` es, en efecto, un LazyFrame de **<font color=\"mediumorchid\">Polars</font>**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6638e1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.lazyframe.frame.LazyFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213f8b7d",
   "metadata": {},
   "source": [
    "Estos objetos son propios de la llamada **lazy API** de **<font color=\"mediumorchid\">Polars</font>**, y que corresponde a una interfaz extremadamente eficiente con el gasto de recursos computacionales a la hora de manipular estructuras de datos. Tal eficiencia llegar al punto de ni siquiera gastar recursos en mostrar los datos almacenados en pantalla al intentar imprimirlos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b30e6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive plan: (run LazyFrame.explain(optimized=True) to see the optimized plan)\n",
      "\n",
      "\n",
      "  CSV SCAN datasets/pillars_data.csv\n",
      "  PROJECT */7 COLUMNS\n"
     ]
    }
   ],
   "source": [
    "# Un LazyFrame no se imprime en pantalla.\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6e7f30",
   "metadata": {},
   "source": [
    "Si queremos, podemos extraer los datos de un LazyFrame por medio del método `fetch()`, usando el parámetro `n_rows` para especificar cuántas filas queremos recuperar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39c41db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌────────────┬────────────┬──────┬──────────┬────────────────┬───────────┬─────────────┐\n",
      "│ x          ┆ y          ┆ z    ┆ area     ┆ frec_fracturas ┆ sigma_z   ┆ tiraje_prom │\n",
      "│ ---        ┆ ---        ┆ ---  ┆ ---      ┆ ---            ┆ ---       ┆ ---         │\n",
      "│ f64        ┆ f64        ┆ i64  ┆ f64      ┆ f64            ┆ f64       ┆ f64         │\n",
      "╞════════════╪════════════╪══════╪══════════╪════════════════╪═══════════╪═════════════╡\n",
      "│ 776.718035 ┆ 259.185135 ┆ 1125 ┆ 286.5643 ┆ 1.979          ┆ 11.126392 ┆ 122.685     │\n",
      "│ 811.143435 ┆ 263.059235 ┆ 1125 ┆ 286.5643 ┆ 3.07           ┆ 9.646313  ┆ 121.178     │\n",
      "│ 845.568835 ┆ 266.933335 ┆ 1125 ┆ 286.5643 ┆ 3.07           ┆ 10.590594 ┆ 118.942     │\n",
      "│ 879.994235 ┆ 270.807435 ┆ 1125 ┆ 286.5643 ┆ 1.75           ┆ 10.605144 ┆ 120.012     │\n",
      "│ 914.419635 ┆ 274.681535 ┆ 1125 ┆ 286.5643 ┆ 0.67           ┆ 10.059537 ┆ 122.787     │\n",
      "└────────────┴────────────┴──────┴──────────┴────────────────┴───────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Recuperamos las 5 primeras filas de nuestro LazyFrame.\n",
    "print(df.fetch(n_rows=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61857954",
   "metadata": {},
   "source": [
    "El acceso a los datos de un archivo `csv` por medio de un escaneo permite igualmente ahorrar tiempo de ejecución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a926b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386 µs ± 28.8 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "109 µs ± 3.58 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pl.read_csv(source=\"datasets/pillars_data.csv\")\n",
    "%timeit pl.scan_csv(source=\"datasets/pillars_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bd4aff",
   "metadata": {},
   "source": [
    "Vemos que `pl.scan_csv()` se ejecuta aproximadamente tres veces más rápido que `pl.read_csv()`.\n",
    "\n",
    "**<font color=\"mediumorchid\">Polars</font>** nos permite cargar datos desde otros tipos de archivos, incluyendo JSON, bases de datos y parquet. Por el momento, nos limitaremos a archivos estáticos propios de máquinas locales como `xlsx` y `csv`, y dejaremos el resto para un momento posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb22cc33",
   "metadata": {},
   "source": [
    "## Iteraciones sobre filas... otra vez.\n",
    "Como en el caso de **<font color=\"mediumorchid\">Pandas</font>**, no es recomendable la iteración por filas en **<font color=\"mediumorchid\">Polars</font>**, ya que no resulta eficiente en términos de tiempos de ejecución. Sin embargo, ello no quiere decir que **<font color=\"mediumorchid\">Polars</font>** no nos ofrezca formad de hacerlo en caso de ser necesario. El método apto para construir iteraciones de este tipo, aplicable sobre series y DataFrames, es `iter_rows()`.\n",
    "\n",
    "`iter_rows()` permite retornar filas de un DataFrame en un formato de tuplas o de diccionarios, de manera similar al método `row()`, dependiendo de si usamos el parámetro Booleano `named`. Sin embargo, la diferencia esencial entre ambos métodos, es que `iter_rows()` nos permite construir **generadores** aptos para cualquier tipo de cálculo iterativo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e95bc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object DataFrame.iter_rows at 0x7fa023a23d60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El método iter_rows() nos permite construir generadores.\n",
    "data.iter_rows(named=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc0c6da",
   "metadata": {},
   "source": [
    "El generador anterior nos permite construir cálculos iterativos de cualquier índole. Por ejemplo, mediante comprensiones de listas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7a86de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.126392, 9.646313, 10.590594, 10.605144, 10.059537]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construimos una lista con los primeros 5 valores del esfuerzo vertical pre-minería\n",
    "# (sigma_z) para cada pilar.\n",
    "[row[\"sigma_z\"] for row in data.head().iter_rows(named=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd9248d",
   "metadata": {},
   "source": [
    "Y, por supuesto, también mediante bucles completos. Para ejemplificar una iteración por filas usando un bucle de tipo `for`, vamos a construir una nueva columna llamada `calidad_roca`, y que categorizará la calidad geotécnica de cada pilar conforme la siguiente clasificación:\n",
    "\n",
    "- Si $FF\\leq 1.25$, entonces la roca es de buena calidad.\n",
    "- Si $FF\\in (1.25,2.25]$, entonces la roca es de calidad regular.\n",
    "- Si $FF>2.25$, entonces la roca es de mala calidad.\n",
    "\n",
    "Lo que haremos será crear esta columna usando el método `iter_rows()`, asignando una categoría correspondiente dependiendo del valor asociado a la columna `frec_fracturas` en cada una de las filas del DataFrame, asignando tales valores a una serie previamente construida, con un tipo de dato conveniente, asignando luego dicha serie como una nueva columna al DataFrame mediante el método `with_columns()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14f00639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos una serie con valores de tipo string iguales a \"a\".\n",
    "s = pl.Series(values=np.full(fill_value=\"a\", shape=data.shape[0]), name=\"calidad_roca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3673359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mediante una iteración por filas, determinamos la categoría asociada a la calidad de\n",
    "# la roca de los pilares y asignamos cada valor a la serie anterior.\n",
    "for i, row_i in enumerate(data.iter_rows(named=True)):\n",
    "    if row_i[\"frec_fracturas\"] <= 1.25:\n",
    "        qa_i = \"Buena calidad\"\n",
    "    elif  row_i[\"frec_fracturas\"] > 2.25:\n",
    "        qa_i = \"Mala calidad\"\n",
    "    else:\n",
    "        qa_i = \"Calidad regular\"\n",
    "    s[i] = qa_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d74360d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos la serie anterior a nuestro DataFrame.\n",
    "data = data.with_columns([s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d26ca02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 8)\n",
      "┌────────────┬────────────┬──────┬──────────┬────────────┬───────────┬─────────────┬───────────────┐\n",
      "│ x          ┆ y          ┆ z    ┆ area     ┆ frec_fract ┆ sigma_z   ┆ tiraje_prom ┆ calidad_roca  │\n",
      "│ ---        ┆ ---        ┆ ---  ┆ ---      ┆ uras       ┆ ---       ┆ ---         ┆ ---           │\n",
      "│ f64        ┆ f64        ┆ i64  ┆ f64      ┆ ---        ┆ f64       ┆ f64         ┆ str           │\n",
      "│            ┆            ┆      ┆          ┆ f64        ┆           ┆             ┆               │\n",
      "╞════════════╪════════════╪══════╪══════════╪════════════╪═══════════╪═════════════╪═══════════════╡\n",
      "│ 776.718035 ┆ 259.185135 ┆ 1125 ┆ 286.5643 ┆ 1.979      ┆ 11.126392 ┆ 122.685     ┆ Calidad       │\n",
      "│            ┆            ┆      ┆          ┆            ┆           ┆             ┆ regular       │\n",
      "│ 811.143435 ┆ 263.059235 ┆ 1125 ┆ 286.5643 ┆ 3.07       ┆ 9.646313  ┆ 121.178     ┆ Mala calidad  │\n",
      "│ 845.568835 ┆ 266.933335 ┆ 1125 ┆ 286.5643 ┆ 3.07       ┆ 10.590594 ┆ 118.942     ┆ Mala calidad  │\n",
      "│ 879.994235 ┆ 270.807435 ┆ 1125 ┆ 286.5643 ┆ 1.75       ┆ 10.605144 ┆ 120.012     ┆ Calidad       │\n",
      "│            ┆            ┆      ┆          ┆            ┆           ┆             ┆ regular       │\n",
      "│ 914.419635 ┆ 274.681535 ┆ 1125 ┆ 286.5643 ┆ 0.67       ┆ 10.059537 ┆ 122.787     ┆ Buena calidad │\n",
      "└────────────┴────────────┴──────┴──────────┴────────────┴───────────┴─────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Mostramos las primeras filas de nuestro DataFrame.\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cf994e",
   "metadata": {},
   "source": [
    "Vamos a replicar todo el proceso anterior por medio de una función, a fin de poder medir el tiempo de ejecución de este procedimiento. Haremos un procedimiento similar en **<font color=\"mediumorchid\">Pandas</font>**, de manera tal que podamos comparar los tiempos de ejecución resultantes en ambas librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79e93f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metemos todo el proceso anterior vía Polars en una función.\n",
    "def classify_rock_qa_polars(data: pl.DataFrame) -> pd.DataFrame:\n",
    "    # Inicializamos una serie con valores de tipo string iguales a \"a\".\n",
    "    s = pl.Series(values=np.full(fill_value=\"a\", shape=data.shape[0]), name=\"calidad_roca\")\n",
    "    \n",
    "    # Mediante una iteración por filas, determinamos la categoría asociada a la calidad de\n",
    "    # la roca de los pilares y asignamos cada valor a la serie anterior.\n",
    "    for i, row_i in enumerate(data.iter_rows(named=True)):\n",
    "        if row_i[\"frec_fracturas\"] <= 1.25:\n",
    "            qa_i = \"Buena calidad\"\n",
    "        elif  row_i[\"frec_fracturas\"] > 2.25:\n",
    "            qa_i = \"Mala calidad\"\n",
    "        else:\n",
    "            qa_i = \"Calidad regular\"\n",
    "        s[i] = qa_i\n",
    "    \n",
    "    # Asignamos la serie anterior a nuestro DataFrame.\n",
    "    data = data.with_columns([s])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de14af63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y también metemos todo en un proceso de Pandas, a fin de comparar.\n",
    "# Una función para iterar por filas en un DataFrame de Pandas y hacer la clasificación.\n",
    "def classify_rock_qa_pandas(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Definimos la nueva columna y la inicializamos con un NaN.\n",
    "    data[\"calidad_roca\"] = np.nan\n",
    "\n",
    "    # Clasificamos los valores de la frecuencia de fracturas mediante un loop.\n",
    "    for row in data.index:\n",
    "        if data.loc[row, \"frec_fracturas\"] <= 1.25:\n",
    "            data.loc[row, \"calidad_roca\"] = \"Buena calidad\"\n",
    "        elif data.loc[row, \"frec_fracturas\"] > 2.25:\n",
    "            data.loc[row, \"calidad_roca\"] = \"Mala calidad\"\n",
    "        else:\n",
    "            data.loc[row, \"calidad_roca\"] = \"Calidad regular\"\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "256d94dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos en un DataFrame de Pandas.\n",
    "df = pd.read_csv(filepath_or_buffer=\"datasets/pillars_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1792361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.8 ms ± 2.11 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "108 ms ± 16.3 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit classify_rock_qa_polars(data)\n",
    "%timeit classify_rock_qa_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c6c04",
   "metadata": {},
   "source": [
    "Vemos pues que, para este caso particular, **<font color=\"mediumorchid\">Polars</font>** es igual de ineficiente que **<font color=\"mediumorchid\">Pandas</font>** a la hora de generar iteraciones por filas sobre DataFrames. Y, además, su sintaxis no resulta en absoluto familiar con respecto a la de **<font color=\"mediumorchid\">Pandas</font>** o, incluso, de **<font color=\"mediumorchid\">Numpy</font>**. Tomaremos ésto como una motivación adicional para hacer todo el esfuerzo posible a fin de vectorizar las operaciones que queramos realizar sobre estructuras de datos de **<font color=\"mediumorchid\">Polars</font>**. La anterior, puntualmente, podemos realizarla fácilmente mediante la función `np.where()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b551930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos nuevamente nuestra data en un DataFrame de Polars, a fin de partir desde cero.\n",
    "data = pl.read_csv(source=\"datasets/pillars_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77fba6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una forma más eficiente de realizar la operación anterior.\n",
    "def classify_rock_qa_vect(data: pl.DataFrame) -> pl.DataFrame:\n",
    "    s = np.where(\n",
    "        data[\"frec_fracturas\"] <= 1.25, \"Buena calidad\",\n",
    "        np.where(data[\"frec_fracturas\"] > 2.25, \"Mala calidad\", \"Calidad regular\")\n",
    "    )\n",
    "    s = pl.Series(values=s)\n",
    "    df = data.with_columns([s.alias(\"calidad_roca\")])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84527987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442 µs ± 23.1 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Revisamos su tiempo de ejecución.\n",
    "%timeit classify_rock_qa_vect(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae03fc4",
   "metadata": {},
   "source": [
    "¡Esta función es más de 200 veces más rápida que la anterior, tras haber evitado la iteración por filas!\n",
    "\n",
    "Y ahora sí, ya podemos crear nuestra columna que permite categorizar la calidad de la roca constituyente de nuestros pilares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9025b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos nuestra función vectorizada.\n",
    "data = classify_rock_qa_vect(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "460d7f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 8)\n",
      "┌────────────┬────────────┬──────┬──────────┬────────────┬───────────┬─────────────┬───────────────┐\n",
      "│ x          ┆ y          ┆ z    ┆ area     ┆ frec_fract ┆ sigma_z   ┆ tiraje_prom ┆ calidad_roca  │\n",
      "│ ---        ┆ ---        ┆ ---  ┆ ---      ┆ uras       ┆ ---       ┆ ---         ┆ ---           │\n",
      "│ f64        ┆ f64        ┆ i64  ┆ f64      ┆ ---        ┆ f64       ┆ f64         ┆ str           │\n",
      "│            ┆            ┆      ┆          ┆ f64        ┆           ┆             ┆               │\n",
      "╞════════════╪════════════╪══════╪══════════╪════════════╪═══════════╪═════════════╪═══════════════╡\n",
      "│ 776.718035 ┆ 259.185135 ┆ 1125 ┆ 286.5643 ┆ 1.979      ┆ 11.126392 ┆ 122.685     ┆ Calidad       │\n",
      "│            ┆            ┆      ┆          ┆            ┆           ┆             ┆ regular       │\n",
      "│ 811.143435 ┆ 263.059235 ┆ 1125 ┆ 286.5643 ┆ 3.07       ┆ 9.646313  ┆ 121.178     ┆ Mala calidad  │\n",
      "│ 845.568835 ┆ 266.933335 ┆ 1125 ┆ 286.5643 ┆ 3.07       ┆ 10.590594 ┆ 118.942     ┆ Mala calidad  │\n",
      "│ 879.994235 ┆ 270.807435 ┆ 1125 ┆ 286.5643 ┆ 1.75       ┆ 10.605144 ┆ 120.012     ┆ Calidad       │\n",
      "│            ┆            ┆      ┆          ┆            ┆           ┆             ┆ regular       │\n",
      "│ 914.419635 ┆ 274.681535 ┆ 1125 ┆ 286.5643 ┆ 0.67       ┆ 10.059537 ┆ 122.787     ┆ Buena calidad │\n",
      "└────────────┴────────────┴──────┴──────────┴────────────┴───────────┴─────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Mostramos las primeras filas de nuestro DataFrame.\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b7daa9",
   "metadata": {},
   "source": [
    "## Agregaciones por agrupamiento.\n",
    "\n",
    "Cuando empezamos a dar nuestros primeros pasos en **<font color=\"mediumorchid\">Polars</font>**, aprendimos que sus estructuras de datos pueden manipularse por medio de dos conjuntos importantes de transformaciones propias de su lenguaje de dominio específico (DSL), denominadas **contextos** y **expresiones**. Dos de los contextos ya fueron revisados en detalle previamente, siendo usados fundamentalmente para seleccionar datos (mediante los métodos `select()` y  `with_columns()`) y filtrarlos (por medio del método `filter()`). No obstante, nos quedó un contexto pendiente y que nos comprometimos a revisar, y que corresponde a la construcción de **agregaciones vía agrupamientos** por medio de los métodos `groupby()` y `agg()`.\n",
    "\n",
    "Bajo el contexto `groupby()`, podemos trabajar cualquier tipo de expresión de **<font color=\"mediumorchid\">Polars</font>** por medio de grupos construidos a partir de categorías existentes en un DataFrame, de tal forma que podamos generar cualquier tipo de agregación a partir de tales grupos. Por ejemplo, en nuestro DataFrame anterior (`data`), podemos usar el contexto `groupby()` para construir cualquier tipo de agregación en función de las categorías previamente construidas para calificar la calidad del macizo rocoso constituyente de cada pilar. La agregación toma como argumento el nombre de la columna que define a los grupos (en nuestro caso, `\"calidad_roca\"`), y luego hace uso del método `agg()` para generar las agregaciones que queramos, debido a que el resultado de la aplicación del método `groupby()` es un objeto preparado para construir tales agregaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67506521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<polars.dataframe.groupby.GroupBy at 0x7fa01f277820>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"calidad_roca\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6a96a2",
   "metadata": {},
   "source": [
    "De esta manera, construiremos la siguiente agregación: Calcularemos el promedio de la carga vertical pre-minería (columna `\"sigma_z\"`) y de la frecuencia de fracturas por metro lineal (columna `\"frec_fracturas\"`), y el máximo valor de tiraje adyacente (columna `\"tiraje_prom\"`) asociados a cada una de las calidades de macizo rocoso previamente definidas. Cada una de estas agregaciones se mostrará con un determinado alias, que definimos en la misma agregación por medio del método `alias()`, de la misma forma en que hicimos con los contextos `select_columns()`, `with_columns()` y `filter()`. La preservación de la **sintaxis contextual** de **<font color=\"mediumorchid\">Polars</font>** es, por supuesto, parte de su lenguaje de dominio específico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9466372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos las agregaciones encadenando al contexto groupby() el método agg().\n",
    "result = data.groupby(\"calidad_roca\").agg(\n",
    "    pl.col(\"sigma_z\").mean().alias(\"avg_sigma_z\"),\n",
    "    pl.col(\"frec_fracturas\").mean().alias(\"avg_frec_fracturas\"),\n",
    "    pl.col(\"tiraje_prom\").max().alias(\"max_tiraje_ady\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57237ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 4)\n",
      "┌─────────────────┬─────────────┬────────────────────┬────────────────┐\n",
      "│ calidad_roca    ┆ avg_sigma_z ┆ avg_frec_fracturas ┆ max_tiraje_ady │\n",
      "│ ---             ┆ ---         ┆ ---                ┆ ---            │\n",
      "│ str             ┆ f64         ┆ f64                ┆ f64            │\n",
      "╞═════════════════╪═════════════╪════════════════════╪════════════════╡\n",
      "│ Calidad regular ┆ 12.355339   ┆ 1.751776           ┆ 193.471        │\n",
      "│ Mala calidad    ┆ 12.192455   ┆ 3.003736           ┆ 192.489        │\n",
      "│ Buena calidad   ┆ 13.552295   ┆ 0.735853           ┆ 201.307        │\n",
      "└─────────────────┴─────────────┴────────────────────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Mostramos el resultado.\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb59a3b0",
   "metadata": {},
   "source": [
    "Vemos pues que el método `agg()` es el ideal para construir cualquier tipo de agregación por medio de un agrupamiento previo conforme alguna columna de interés que sea categórica. \n",
    "\n",
    "Existen otras opciones para generar agregaciones de mayor complejidad. Por ejemplo, podemos hacer uso del método `apply()` sobre una agrupación realizada previamente con el contexto `groupby()` para construir un cálculo usando cualquier función que deseemos, similar a lo que ya hemos hecho usando la librería **<font color=\"mediumorchid\">Pandas</font>**. Sin embargo, no lo haremos acá porque, como veremos más adelante, será mucho más eficiente realizar tales cálculos de este tipo aprovechando las **expresiones** provistas por **<font color=\"mediumorchid\">Polars</font>**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12542efe",
   "metadata": {},
   "source": [
    "## Expresiones.\n",
    "\n",
    "El pilar fundamental de la rapidez de **<font color=\"mediumorchid\">Polars</font>** a la hora de realizar cualquier tipo de manipulación de sus estructuras de datos radica en las llamadas **expresiones**, y que, al igual que los contextos, son parte integral de su lenguaje de dominio específico (DSL). Estas expresiones representan una enorme cantidad de operaciones que podemos realizar sobre estructuras de datos de **<font color=\"mediumorchid\">Polars</font>**. Por ejemplo:\n",
    "\n",
    "- Extraer una muestra aleatoria de distintas filas de un DataFrame.\n",
    "- Multiplicar los valores de una columna en un DataFrame por algún escalar.\n",
    "- Extraer una columna que contenga los años que definen los *timestamps* definidos en otra columna en un determinado DataFrame.\n",
    "- Convertir una columna de valores de tipo string en otra que elimine ciertos caracteres problemáticos (por ejemplo, que transforme cualquier caracter en mayúsculas en el mismo, pero en minúsculas).\n",
    "\n",
    "**<font color=\"mediumorchid\">Polars</font>** implementa las operaciones definidas por expresiones muy rápido, paralelizando tales operaciones cuando éstas se definen para varias columnas en un DataFrame. Estas expresiones pueden idearse como aplicaciones cuyo dominio y codominio son series de **<font color=\"mediumorchid\">Polars</font>**, lo que permite manpipular los datos almacenados en un DataFrame encadenando estas expresiones serie a serie (o columna a columna).\n",
    "\n",
    "Al mostrar previamente los contextos de **<font color=\"mediumorchid\">Polars</font>**, ya trabajamos con expresiones, aunque nunca las definimos formalmente. Por ejemplo, definimos el siguiente filtro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf50c2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (12, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x</th><th>y</th><th>z</th><th>area</th><th>frec_fracturas</th><th>sigma_z</th><th>tiraje_prom</th><th>calidad_roca</th></tr><tr><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>1052.121235</td><td>290.177935</td><td>1125</td><td>286.9684</td><td>3.07</td><td>20.386906</td><td>119.57</td><td>&quot;Mala calidad&quot;</td></tr><tr><td>1086.546635</td><td>294.052035</td><td>1125</td><td>285.655</td><td>3.07</td><td>26.811494</td><td>123.548</td><td>&quot;Mala calidad&quot;</td></tr><tr><td>1080.540535</td><td>280.294935</td><td>1125</td><td>285.7422</td><td>3.07</td><td>24.334748</td><td>122.197</td><td>&quot;Mala calidad&quot;</td></tr><tr><td>1114.965935</td><td>284.169135</td><td>1125</td><td>248.9047</td><td>3.07</td><td>25.943104</td><td>126.022</td><td>&quot;Mala calidad&quot;</td></tr><tr><td>1108.959835</td><td>270.410235</td><td>1125</td><td>286.5643</td><td>3.07</td><td>25.763218</td><td>125.252</td><td>&quot;Mala calidad&quot;</td></tr><tr><td>1102.952735</td><td>256.652235</td><td>1125</td><td>286.5643</td><td>3.07</td><td>21.843244</td><td>126.931</td><td>&quot;Mala calidad&quot;</td></tr><tr><td>1190.809535</td><td>84.682135</td><td>1125</td><td>183.5212</td><td>3.07</td><td>20.67544</td><td>141.254</td><td>&quot;Mala calidad&quot;</td></tr><tr><td>1275.050635</td><td>-95.653065</td><td>1125</td><td>644.9389</td><td>3.07</td><td>22.167532</td><td>148.145</td><td>&quot;Mala calidad&quot;</td></tr><tr><td>1366.417235</td><td>-94.689765</td><td>1125</td><td>557.4125</td><td>3.07</td><td>26.730452</td><td>147.198</td><td>&quot;Mala calidad&quot;</td></tr><tr><td>1336.637035</td><td>-94.482565</td><td>1125</td><td>550.7097</td><td>3.07</td><td>27.14646</td><td>145.482</td><td>&quot;Mala calidad&quot;</td></tr><tr><td>1306.064735</td><td>-94.064965</td><td>1125</td><td>526.795</td><td>3.07</td><td>25.1711</td><td>145.567</td><td>&quot;Mala calidad&quot;</td></tr><tr><td>1335.505435</td><td>-115.879465</td><td>1125</td><td>347.5708</td><td>2.47</td><td>20.350308</td><td>144.021</td><td>&quot;Mala calidad&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (12, 8)\n",
       "┌──────────────┬─────────────┬──────┬──────────┬────────────┬───────────┬─────────────┬────────────┐\n",
       "│ x            ┆ y           ┆ z    ┆ area     ┆ frec_fract ┆ sigma_z   ┆ tiraje_prom ┆ calidad_ro │\n",
       "│ ---          ┆ ---         ┆ ---  ┆ ---      ┆ uras       ┆ ---       ┆ ---         ┆ ca         │\n",
       "│ f64          ┆ f64         ┆ i64  ┆ f64      ┆ ---        ┆ f64       ┆ f64         ┆ ---        │\n",
       "│              ┆             ┆      ┆          ┆ f64        ┆           ┆             ┆ str        │\n",
       "╞══════════════╪═════════════╪══════╪══════════╪════════════╪═══════════╪═════════════╪════════════╡\n",
       "│ 1052.121235  ┆ 290.177935  ┆ 1125 ┆ 286.9684 ┆ 3.07       ┆ 20.386906 ┆ 119.57      ┆ Mala       │\n",
       "│              ┆             ┆      ┆          ┆            ┆           ┆             ┆ calidad    │\n",
       "│ 1086.546635  ┆ 294.052035  ┆ 1125 ┆ 285.655  ┆ 3.07       ┆ 26.811494 ┆ 123.548     ┆ Mala       │\n",
       "│              ┆             ┆      ┆          ┆            ┆           ┆             ┆ calidad    │\n",
       "│ 1080.540535  ┆ 280.294935  ┆ 1125 ┆ 285.7422 ┆ 3.07       ┆ 24.334748 ┆ 122.197     ┆ Mala       │\n",
       "│              ┆             ┆      ┆          ┆            ┆           ┆             ┆ calidad    │\n",
       "│ 1114.965935  ┆ 284.169135  ┆ 1125 ┆ 248.9047 ┆ 3.07       ┆ 25.943104 ┆ 126.022     ┆ Mala       │\n",
       "│              ┆             ┆      ┆          ┆            ┆           ┆             ┆ calidad    │\n",
       "│ …            ┆ …           ┆ …    ┆ …        ┆ …          ┆ …         ┆ …           ┆ …          │\n",
       "│ 1366.417235  ┆ -94.689765  ┆ 1125 ┆ 557.4125 ┆ 3.07       ┆ 26.730452 ┆ 147.198     ┆ Mala       │\n",
       "│              ┆             ┆      ┆          ┆            ┆           ┆             ┆ calidad    │\n",
       "│ 1336.637035  ┆ -94.482565  ┆ 1125 ┆ 550.7097 ┆ 3.07       ┆ 27.14646  ┆ 145.482     ┆ Mala       │\n",
       "│              ┆             ┆      ┆          ┆            ┆           ┆             ┆ calidad    │\n",
       "│ 1306.064735  ┆ -94.064965  ┆ 1125 ┆ 526.795  ┆ 3.07       ┆ 25.1711   ┆ 145.567     ┆ Mala       │\n",
       "│              ┆             ┆      ┆          ┆            ┆           ┆             ┆ calidad    │\n",
       "│ 1335.505435  ┆ -115.879465 ┆ 1125 ┆ 347.5708 ┆ 2.47       ┆ 20.350308 ┆ 144.021     ┆ Mala       │\n",
       "│              ┆             ┆      ┆          ┆            ┆           ┆             ┆ calidad    │\n",
       "└──────────────┴─────────────┴──────┴──────────┴────────────┴───────────┴─────────────┴────────────┘"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Un filtro sencillo que se define a partir de una expresión.\n",
    "data.filter((pl.col(\"calidad_roca\") == \"Mala calidad\") & (pl.col(\"sigma_z\") >= 20.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560737b1",
   "metadata": {},
   "source": [
    "En el filtro anterior, la **expresión** que permite a **<font color=\"mediumorchid\">Polars</font>** transformar el DataFrame `data` en una versión filtrada del mismo es `(pl.col(\"calidad_roca\") == \"Mala calidad\") & (pl.col(\"sigma_z\") >= 20.0)`. Tal expresión es la combinación de otras dos expresiones más simples, que son `pl.col(\"calidad_roca\") == \"Mala calidad\"` y `pl.col(\"sigma_z\") >= 20.0`.\n",
    "\n",
    "Las selecciones de datos en DataFrames también trabajan conforme expresiones, las que a su vez implementan las transformaciones que queremos realizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de5d197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las selecciones también trabajan conforme expresiones.\n",
    "data_2 = data.select(\n",
    "    [\n",
    "        (np.sqrt(pl.col(\"x\")**2 + pl.col(\"y\")**2)).alias(\"r\"),\n",
    "        (np.rad2deg(np.arctan(pl.col(\"y\") / pl.col(\"x\")))).alias(\"theta\"),\n",
    "        (pl.col(\"area\") * pl.col(\"frec_fracturas\")).alias(\"p32\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d613981f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌────────────┬───────────┬────────────┐\n",
      "│ r          ┆ theta     ┆ p32        │\n",
      "│ ---        ┆ ---       ┆ ---        │\n",
      "│ f64        ┆ f64       ┆ f64        │\n",
      "╞════════════╪═══════════╪════════════╡\n",
      "│ 818.821007 ┆ 18.453478 ┆ 567.11075  │\n",
      "│ 852.733155 ┆ 17.968225 ┆ 879.752401 │\n",
      "│ 886.701788 ┆ 17.520121 ┆ 879.752401 │\n",
      "│ 920.720653 ┆ 17.105107 ┆ 501.487525 │\n",
      "│ 954.784382 ┆ 16.719686 ┆ 191.998081 │\n",
      "└────────────┴───────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Imprimimos las primeras filas de este nuevo DataFrame.\n",
    "print(data_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db371556",
   "metadata": {},
   "source": [
    "En la selección anterior, que da lugar a un nuevo DataFrame, las **expresiones** que nos permiten llegar al resultado deseado son las siguientes:\n",
    "\n",
    "- `(np.sqrt(pl.col(\"x\")**2 + pl.col(\"y\")**2)).alias(\"r\")`, que permite construir la coordenada radial $r=x^{2}+y^{2}$ propia de un sistema de coordenadas polares para los pilares. Tal expresión es compuesta, ya que se ha construido a partir de las expresiones `pl.col(\"x\")**2` y `pl.col(\"y\")**2`.\n",
    "- `(np.rad2deg(np.arctan(pl.col(\"y\") / pl.col(\"x\")))).alias(\"theta\")`, que permite construir la coordenada transversal $\\theta = \\arctan(y/x)$ propia de un sistema de coordenadas polares para los pilares. Esta expresión también es compuesta, porque igualmente depende de las expresiones `pl.col(\"x\")**2` y `pl.col(\"y\")**2`.\n",
    "- `(pl.col(\"area\") * pl.col(\"frec_fracturas\")).alias(\"p32\")`, que permite construir una estimación de la frecuencia de fracturas por superficie del pilar completa (en metros cuadrados por metro lineal, y que típicamente se denomina $P_{32}$. Esta expresión también es compuesta, ya que depende de las expresiones `pl.col(\"area\")` y `pl.col(\"frec_fracturas\")`.\n",
    "\n",
    "Cada una de las expresiones anteriores se ejecuta en paralelo, a fin de maximizar la eficiencia en el tiempo de ejecución del contexto completo. Esta es una de las grandes diferencias que tiene **<font color=\"mediumorchid\">Polars</font>** en relación a **<font color=\"mediumorchid\">Pandas</font>**.\n",
    "\n",
    "### Operatoria básica.\n",
    "Con *operaciones básicas* nos referimos al conjunto de todas las operaciones que son expresables por medio de operadores sencillos. Ejemplos de este tipo de operaciones son la suma (`+`), resta (`-`), multiplicación (`*`) y división (`/`) para el caso de **datos de tipo numérico**, y la disyunción (`&`) y conjunción (`|`) lógicas para el caso de **data de tipo string o no numérica**.\n",
    "\n",
    "Vamos a ejemplificar el uso más fundamental de estos operadores para el caso numérico. Para ello, crearemos algunas series de **<font color=\"mediumorchid\">Polars</font>** a partir de arreglos aleatorizados de **<font color=\"mediumorchid\">Numpy</font>**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a9aed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos una semilla aleatoria fija.\n",
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71ebe09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos unos arreglos unidimensionales a partir de los cuales generaremos algunas series.\n",
    "a1 = rng.uniform(low=-1, high=1, size=10)\n",
    "a2 = rng.normal(loc=0, scale=1, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3e7315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos una serie de Polars a partir del arreglo anterior.\n",
    "s1 = pl.Series(values=a1, name=\"x1\")\n",
    "s2 = pl.Series(values=a2, name=\"x2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54543cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x1</th></tr><tr><td>f64</td></tr></thead><tbody><tr><td>0.547912</td></tr><tr><td>-0.122243</td></tr><tr><td>0.717196</td></tr><tr><td>0.394736</td></tr><tr><td>-0.811645</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5,)\n",
       "Series: 'x1' [f64]\n",
       "[\n",
       "\t0.547912\n",
       "\t-0.122243\n",
       "\t0.717196\n",
       "\t0.394736\n",
       "\t-0.811645\n",
       "]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos las primeras filas de la serie s1 en pantalla.\n",
    "s1.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84983e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x2</th></tr><tr><td>f64</td></tr></thead><tbody><tr><td>0.879398</td></tr><tr><td>0.777792</td></tr><tr><td>0.066031</td></tr><tr><td>1.127241</td></tr><tr><td>0.467509</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5,)\n",
       "Series: 'x2' [f64]\n",
       "[\n",
       "\t0.879398\n",
       "\t0.777792\n",
       "\t0.066031\n",
       "\t1.127241\n",
       "\t0.467509\n",
       "]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos las primeras filas de la serie s2 en pantalla.\n",
    "s2.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b50bb8",
   "metadata": {},
   "source": [
    "Luego, para el caso de la suma (`+`) y la multiplicación (`*`), tenemos que:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2951387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x1</th></tr><tr><td>f64</td></tr></thead><tbody><tr><td>1.42731</td></tr><tr><td>0.655549</td></tr><tr><td>0.783227</td></tr><tr><td>1.521977</td></tr><tr><td>-0.344136</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5,)\n",
       "Series: 'x1' [f64]\n",
       "[\n",
       "\t1.42731\n",
       "\t0.655549\n",
       "\t0.783227\n",
       "\t1.521977\n",
       "\t-0.344136\n",
       "]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suma de las series s1 y s2.\n",
    "(s1 + s2).head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc7a4731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x1</th></tr><tr><td>f64</td></tr></thead><tbody><tr><td>0.481833</td></tr><tr><td>-0.09508</td></tr><tr><td>0.047357</td></tr><tr><td>0.444963</td></tr><tr><td>-0.379452</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5,)\n",
       "Series: 'x1' [f64]\n",
       "[\n",
       "\t0.481833\n",
       "\t-0.09508\n",
       "\t0.047357\n",
       "\t0.444963\n",
       "\t-0.379452\n",
       "]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplicación de las series s1 y s2.\n",
    "(s1 * s2).head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8e12a2",
   "metadata": {},
   "source": [
    "Podemos observar que, si bien ésto no se explicita, **<font color=\"mediumorchid\">Polars</font>** alinea las correspondientes series en términos de las posiciones relativas que ocupan cada una de sus filas.\n",
    "\n",
    "Las operaciones de este tipo suelen aplicarse conforme el lenguaje de dominio específico de **<font color=\"mediumorchid\">Polars</font>** por medio de expresiones bajo un contexto determinado. Por ejemplo, si creamos un DataFrame a partir de un arreglo bidimensional aleatoriamente definido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8923b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un arreglo bidimensional aleatorizado (con números normalmente distribuidos).\n",
    "d1 = rng.normal(loc=0, scale=1, size=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ed88e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un DataFrame a partir del arreglo anterior.\n",
    "df1 = pl.DataFrame(data=d1, schema=[f\"x{j}\" for j in range(1, 6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bfbf8e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 5)\n",
      "┌───────────┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ x1        ┆ x2        ┆ x3        ┆ x4        ┆ x5       │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
      "│ f64       ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ -0.184862 ┆ -0.352134 ┆ 2.141648  ┆ 1.128972  ┆ 0.743254 │\n",
      "│ -0.68093  ┆ 0.532309  ┆ -0.406415 ┆ -0.113947 ┆ 0.543154 │\n",
      "│ 1.222541  ┆ 0.365444  ┆ -0.512243 ┆ -0.840156 ┆ -0.66551 │\n",
      "│ -0.154529 ┆ 0.412733  ┆ -0.813773 ┆ -0.824481 ┆ 0.232161 │\n",
      "│ -0.428328 ┆ 0.430821  ┆ 0.615979  ┆ 0.650593  ┆ 0.116686 │\n",
      "└───────────┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# Mostramos este DataFrame en pantalla.\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4049db",
   "metadata": {},
   "source": [
    "Entonces podemos usar expresiones simples para generar las siguientes operaciones aritméticas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0365b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicación de operaciones sencillas por medio de expresiones encadenadas en un contexto.\n",
    "result = df1.select(\n",
    "    [\n",
    "        # Multiplicamos la columna x1 por 2 y luego le sumamos 10.\n",
    "        (pl.col(\"x1\") * 2 + 10).alias(\"2x1 + 10\"),\n",
    "        # Dividimos las columnas x2 y x4, y el resultado se lo sumamos a x5.\n",
    "        (pl.col(\"x2\") / pl.col(\"x4\") + pl.col(\"x5\")).alias(\"x2/x4 + x5\"),\n",
    "        # Sumamos la columna x1 con el triple de la columna x5, y el resultado\n",
    "        # lo dividimos por 3.\n",
    "        ((pl.col(\"x1\") + 3 * pl.col(\"x5\")) * 3).alias(\"3(x1 + 3x5)\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59b98022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌───────────┬────────────┬─────────────┐\n",
      "│ 2x1 + 10  ┆ x2/x4 + x5 ┆ 3(x1 + 3x5) │\n",
      "│ ---       ┆ ---        ┆ ---         │\n",
      "│ f64       ┆ f64        ┆ f64         │\n",
      "╞═══════════╪════════════╪═════════════╡\n",
      "│ 9.630275  ┆ 0.431348   ┆ 6.1347      │\n",
      "│ 8.638141  ┆ -4.128378  ┆ 2.8456      │\n",
      "│ 12.445083 ┆ -1.100481  ┆ -2.321963   │\n",
      "│ 9.690941  ┆ -0.268435  ┆ 1.625863    │\n",
      "│ 9.143344  ┆ 0.778883   ┆ -0.234811   │\n",
      "└───────────┴────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Mostramos el resultado anterior.\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf493c05",
   "metadata": {},
   "source": [
    "Las operaciones de comparación también son sencillas de implementar por medio de expresiones. Por ejemplo, para el caso del DataFrame `data`, que contiene la información relativa a los pilares que trabajamos con anterioridad, podemos generar un contexto que admita este tipo de expresiones a fin de construir un resultado Booleano que puede utilizarse fácilmente como filtro para otras operaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "641d034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicación de operaciones de comparación sencillas por medio de expresiones \n",
    "# encadenadas en un contexto.\n",
    "result = data.select(\n",
    "    [\n",
    "        # Todos los pilares cuya área sea menor o igual que 250 m^2.\n",
    "        (pl.col(\"area\") <= 250).alias(\"area <= 250 m^2\"),\n",
    "        # Todos los pilares cuya calidad geotécnica sea mala.\n",
    "        (pl.col(\"calidad_roca\") == \"Mala calidad\").alias(\"calidad == mala\"),\n",
    "        # Todos los pilares cuya carga vertical pre-minería sea mayor que 18 MPa.\n",
    "        (pl.col(\"sigma_z\") > 18.0).alias(\"sigma_z > 18 MPa\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c31598ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌─────────────────┬─────────────────┬──────────────────┐\n",
      "│ area <= 250 m^2 ┆ calidad == mala ┆ sigma_z > 18 MPa │\n",
      "│ ---             ┆ ---             ┆ ---              │\n",
      "│ bool            ┆ bool            ┆ bool             │\n",
      "╞═════════════════╪═════════════════╪══════════════════╡\n",
      "│ false           ┆ false           ┆ false            │\n",
      "│ false           ┆ true            ┆ false            │\n",
      "│ false           ┆ true            ┆ false            │\n",
      "│ false           ┆ false           ┆ false            │\n",
      "│ false           ┆ false           ┆ false            │\n",
      "└─────────────────┴─────────────────┴──────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Mostramos las primeras filas del resultado anterior.\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d5c6fc",
   "metadata": {},
   "source": [
    "Por supuesto, es posible construir infinitas expresiones de acuerdo a las condiciones del problema particular que queramos abordar, usando operadores fundamentales tanto aritméticos como de comparación. Los anteriores fueron simplemente ejemplos sencillos de lo mucho que podemos hacer al manipular estructuras de datos vía contextos y expresiones básicas en **<font color=\"mediumorchid\">Polars</font>**.\n",
    "\n",
    "### Funciones aplicables sobre DataFrames.\n",
    "Las expresiones de **<font color=\"mediumorchid\">Polars</font>** nos ofrecen un gran número de funciones y/o rutinas pre-establecidas que nos permiten construir *queries* o consultas de datos de enorme complejidad, sin tener que recurrir a funciones definidas por nosotros y que, en muchos casos, tendrán un tiempo de ejecución nativo de Python y por consiguiente no serán igual de rápidas que las rutinas nativas de **<font color=\"mediumorchid\">Polars</font>**.\n",
    "\n",
    "Estas rutinas son todas aplicables en un contexto de selección de datos (por ejemplo, vía `select()` o `with_columns()`).\n",
    "\n",
    "A fin de aprender algunas de estas funciones, vamos a construir un DataFrame que simulará algunos datos operacionales relativos a una planta de flotación, durante un total de 1000 horas (una hora por registro):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9165691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construiremos el DataFrame a partir de nuestra semilla aleatoria fija.\n",
    "df_flot = pl.DataFrame(\n",
    "    {\n",
    "        \"ley_alim\": rng.normal(loc=0.8, scale=0.2, size=1000),\n",
    "        \"alim_flot\": rng.normal(loc=2000, scale=250, size=1000),\n",
    "        \"sol_alim\": rng.uniform(low=38, high=44, size=1000),\n",
    "        \"num_cells_off\": rng.poisson(lam=0.5, size=1000),\n",
    "        \"niv_med_esp\": rng.uniform(low=10, high=60, size=1000),\n",
    "        \"dif_niv_esp\": rng.uniform(low=-30, high=10, size=1000),\n",
    "        \"ley_conc\": rng.uniform(low=28.5, high=31.5, size=1000),\n",
    "        \"ley_cola\": rng.normal(loc=0.03, scale=0.005, size=1000)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bfc574ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 8)\n",
      "┌──────────┬─────────────┬───────────┬────────────┬───────────┬─────────────┬───────────┬──────────┐\n",
      "│ ley_alim ┆ alim_flot   ┆ sol_alim  ┆ num_cells_ ┆ niv_med_e ┆ dif_niv_esp ┆ ley_conc  ┆ ley_cola │\n",
      "│ ---      ┆ ---         ┆ ---       ┆ off        ┆ sp        ┆ ---         ┆ ---       ┆ ---      │\n",
      "│ f64      ┆ f64         ┆ f64       ┆ ---        ┆ ---       ┆ f64         ┆ f64       ┆ f64      │\n",
      "│          ┆             ┆           ┆ i64        ┆ f64       ┆             ┆           ┆          │\n",
      "╞══════════╪═════════════╪═══════════╪════════════╪═══════════╪═════════════╪═══════════╪══════════╡\n",
      "│ 0.843738 ┆ 1785.198495 ┆ 43.115736 ┆ 3          ┆ 45.186831 ┆ -24.029143  ┆ 29.189195 ┆ 0.028975 │\n",
      "│ 0.974286 ┆ 1865.584356 ┆ 41.431704 ┆ 0          ┆ 59.507281 ┆ 7.177497    ┆ 29.857525 ┆ 0.026371 │\n",
      "│ 0.844719 ┆ 2135.648616 ┆ 39.282985 ┆ 0          ┆ 22.131268 ┆ -15.446129  ┆ 29.558203 ┆ 0.024677 │\n",
      "│ 0.935783 ┆ 1761.093708 ┆ 43.400548 ┆ 0          ┆ 23.711929 ┆ -25.952022  ┆ 28.854379 ┆ 0.020639 │\n",
      "│ 0.813516 ┆ 2109.378062 ┆ 40.055902 ┆ 0          ┆ 50.676327 ┆ -23.01264   ┆ 31.332929 ┆ 0.023267 │\n",
      "└──────────┴─────────────┴───────────┴────────────┴───────────┴─────────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# Mostramos las primeras filas de este DataFrame\n",
    "print(df_flot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f96565b",
   "metadata": {},
   "source": [
    "Las columnas de este DataFrame representan la siguiente información:\n",
    "\n",
    "- `ley_alim`: Ley de cobre de alimentación de la planta (% Cu).\n",
    "- `alim_flot`: Tonelaje de mineral que entra a la planta de flotación (tph).\n",
    "- `sol_alim`: Porcentaje de sólidos en la alimentación de la planta (%).\n",
    "- `num_cells_off`: Número de celdas en el circuito que se encuentran fuera de servicio.\n",
    "- `niv_med_esp`: Valor medio de espesor de espuma en el circuito (mm).\n",
    "- `dif_niv_esp`: Diferencia de espesores de espuma entre el primer y el último banco en el circuito (mm).\n",
    "- `ley_conc`: Ley de concentrado resultante del proceso (% Cu).\n",
    "- `ley_cola`: Ley de relave resultante del proceso (% Cu).\n",
    "\n",
    "Crearemos algunas variables categóricas adicionales en este DataFrame, a fin de contar con información numérica que será útil para mostrar la implementación de algunas rutinas nativas de **<font color=\"mediumorchid\">Polars</font>**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f54cab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos categorías para leyes de relave.\n",
    "s1 = pl.Series(\n",
    "    values=np.where(\n",
    "        df_flot[\"ley_cola\"] >= 0.038, \"Relaves con alta ley\", \"Relaves controlados\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eda1f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos categorías para los niveles de espuma en la pulpa.\n",
    "s2 = pl.Series(\n",
    "    values=np.where(\n",
    "        df_flot[\"dif_niv_esp\"] >= 0, \n",
    "        \"Perfil no recuperativo\",\n",
    "        np.where(\n",
    "            df_flot[\"dif_niv_esp\"] < -15.0,\n",
    "            \"Perfil muy recuperativo\",\n",
    "            \"Perfil medianamente recuperativo\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d8df524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añádimos esta información a nuestro DataFrame.\n",
    "df_flot = df_flot.with_columns([\n",
    "    s1.alias(\"cond_relaves\"), s2.alias(\"perfil_niveles\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68b947d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ley_alim</th><th>alim_flot</th><th>sol_alim</th><th>num_cells_off</th><th>niv_med_esp</th><th>dif_niv_esp</th><th>ley_conc</th><th>ley_cola</th><th>cond_relaves</th><th>perfil_niveles</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0.843738</td><td>1785.198495</td><td>43.115736</td><td>3</td><td>45.186831</td><td>-24.029143</td><td>29.189195</td><td>0.028975</td><td>&quot;Relaves contro…</td><td>&quot;Perfil muy rec…</td></tr><tr><td>0.974286</td><td>1865.584356</td><td>41.431704</td><td>0</td><td>59.507281</td><td>7.177497</td><td>29.857525</td><td>0.026371</td><td>&quot;Relaves contro…</td><td>&quot;Perfil no recu…</td></tr><tr><td>0.844719</td><td>2135.648616</td><td>39.282985</td><td>0</td><td>22.131268</td><td>-15.446129</td><td>29.558203</td><td>0.024677</td><td>&quot;Relaves contro…</td><td>&quot;Perfil muy rec…</td></tr><tr><td>0.935783</td><td>1761.093708</td><td>43.400548</td><td>0</td><td>23.711929</td><td>-25.952022</td><td>28.854379</td><td>0.020639</td><td>&quot;Relaves contro…</td><td>&quot;Perfil muy rec…</td></tr><tr><td>0.813516</td><td>2109.378062</td><td>40.055902</td><td>0</td><td>50.676327</td><td>-23.01264</td><td>31.332929</td><td>0.023267</td><td>&quot;Relaves contro…</td><td>&quot;Perfil muy rec…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌──────────┬─────────┬───────────┬────────────┬───┬───────────┬──────────┬────────────┬────────────┐\n",
       "│ ley_alim ┆ alim_fl ┆ sol_alim  ┆ num_cells_ ┆ … ┆ ley_conc  ┆ ley_cola ┆ cond_relav ┆ perfil_niv │\n",
       "│ ---      ┆ ot      ┆ ---       ┆ off        ┆   ┆ ---       ┆ ---      ┆ es         ┆ eles       │\n",
       "│ f64      ┆ ---     ┆ f64       ┆ ---        ┆   ┆ f64       ┆ f64      ┆ ---        ┆ ---        │\n",
       "│          ┆ f64     ┆           ┆ i64        ┆   ┆           ┆          ┆ str        ┆ str        │\n",
       "╞══════════╪═════════╪═══════════╪════════════╪═══╪═══════════╪══════════╪════════════╪════════════╡\n",
       "│ 0.843738 ┆ 1785.19 ┆ 43.115736 ┆ 3          ┆ … ┆ 29.189195 ┆ 0.028975 ┆ Relaves    ┆ Perfil muy │\n",
       "│          ┆ 8495    ┆           ┆            ┆   ┆           ┆          ┆ controlado ┆ recuperati │\n",
       "│          ┆         ┆           ┆            ┆   ┆           ┆          ┆ s          ┆ vo         │\n",
       "│ 0.974286 ┆ 1865.58 ┆ 41.431704 ┆ 0          ┆ … ┆ 29.857525 ┆ 0.026371 ┆ Relaves    ┆ Perfil no  │\n",
       "│          ┆ 4356    ┆           ┆            ┆   ┆           ┆          ┆ controlado ┆ recuperati │\n",
       "│          ┆         ┆           ┆            ┆   ┆           ┆          ┆ s          ┆ vo         │\n",
       "│ 0.844719 ┆ 2135.64 ┆ 39.282985 ┆ 0          ┆ … ┆ 29.558203 ┆ 0.024677 ┆ Relaves    ┆ Perfil muy │\n",
       "│          ┆ 8616    ┆           ┆            ┆   ┆           ┆          ┆ controlado ┆ recuperati │\n",
       "│          ┆         ┆           ┆            ┆   ┆           ┆          ┆ s          ┆ vo         │\n",
       "│ 0.935783 ┆ 1761.09 ┆ 43.400548 ┆ 0          ┆ … ┆ 28.854379 ┆ 0.020639 ┆ Relaves    ┆ Perfil muy │\n",
       "│          ┆ 3708    ┆           ┆            ┆   ┆           ┆          ┆ controlado ┆ recuperati │\n",
       "│          ┆         ┆           ┆            ┆   ┆           ┆          ┆ s          ┆ vo         │\n",
       "│ 0.813516 ┆ 2109.37 ┆ 40.055902 ┆ 0          ┆ … ┆ 31.332929 ┆ 0.023267 ┆ Relaves    ┆ Perfil muy │\n",
       "│          ┆ 8062    ┆           ┆            ┆   ┆           ┆          ┆ controlado ┆ recuperati │\n",
       "│          ┆         ┆           ┆            ┆   ┆           ┆          ┆ s          ┆ vo         │\n",
       "└──────────┴─────────┴───────────┴────────────┴───┴───────────┴──────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos las primeras filas del DataFrame.\n",
    "df_flot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa3ac5",
   "metadata": {},
   "source": [
    "Una de las rutinas nativas de **<font color=\"mediumorchid\">Polars</font>** más elementales corresponde a `select()`, que sabemos que corresponde al método contextual preferido para seleccionar información de un DataFrame. Es posible seleccionar un número arbitrario de columnas a partir de este contexto, incluyendo todas las columnas del DataFrame en cuestión. Para esto último, basta con usar la expresión `pl.col(\"*\")`, que es equivalente al uso del símbolo `:` en **<font color=\"mediumorchid\">Numpy</font>** para recuperar todos los elementos relativos al eje de un arreglo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f88e2457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de todas las columnas en un DataFrame.\n",
    "selection = df_flot.select([pl.col(\"*\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2db1e722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Efectivamente, la selección anterior equivale al mismo DataFrame, ya que tiene sus mismas dimensiones.\n",
    "selection.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c20dcf",
   "metadata": {},
   "source": [
    "Otra rutina muy usada en **<font color=\"mediumorchid\">Polars</font>** corresponde a `exclude()`, y que nos permite seleccionar un número arbitrario de columnas en un DataFrame, exceptuando a un grupo determinado de columnas que especificamos por su nombre en caso de ser sólo una, o por medio de una lista de Python en el caso de ser más de una:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67f4e4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluimos tres columnas de nuestro DataFrame en esta selección.\n",
    "selection = df_flot.select([pl.exclude([\"cond_relaves\", \"perfil_niveles\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d7da6a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ley_alim</th><th>alim_flot</th><th>sol_alim</th><th>num_cells_off</th><th>niv_med_esp</th><th>dif_niv_esp</th><th>ley_conc</th><th>ley_cola</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.843738</td><td>1785.198495</td><td>43.115736</td><td>3</td><td>45.186831</td><td>-24.029143</td><td>29.189195</td><td>0.028975</td></tr><tr><td>0.974286</td><td>1865.584356</td><td>41.431704</td><td>0</td><td>59.507281</td><td>7.177497</td><td>29.857525</td><td>0.026371</td></tr><tr><td>0.844719</td><td>2135.648616</td><td>39.282985</td><td>0</td><td>22.131268</td><td>-15.446129</td><td>29.558203</td><td>0.024677</td></tr><tr><td>0.935783</td><td>1761.093708</td><td>43.400548</td><td>0</td><td>23.711929</td><td>-25.952022</td><td>28.854379</td><td>0.020639</td></tr><tr><td>0.813516</td><td>2109.378062</td><td>40.055902</td><td>0</td><td>50.676327</td><td>-23.01264</td><td>31.332929</td><td>0.023267</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 8)\n",
       "┌──────────┬─────────────┬───────────┬────────────┬───────────┬─────────────┬───────────┬──────────┐\n",
       "│ ley_alim ┆ alim_flot   ┆ sol_alim  ┆ num_cells_ ┆ niv_med_e ┆ dif_niv_esp ┆ ley_conc  ┆ ley_cola │\n",
       "│ ---      ┆ ---         ┆ ---       ┆ off        ┆ sp        ┆ ---         ┆ ---       ┆ ---      │\n",
       "│ f64      ┆ f64         ┆ f64       ┆ ---        ┆ ---       ┆ f64         ┆ f64       ┆ f64      │\n",
       "│          ┆             ┆           ┆ i64        ┆ f64       ┆             ┆           ┆          │\n",
       "╞══════════╪═════════════╪═══════════╪════════════╪═══════════╪═════════════╪═══════════╪══════════╡\n",
       "│ 0.843738 ┆ 1785.198495 ┆ 43.115736 ┆ 3          ┆ 45.186831 ┆ -24.029143  ┆ 29.189195 ┆ 0.028975 │\n",
       "│ 0.974286 ┆ 1865.584356 ┆ 41.431704 ┆ 0          ┆ 59.507281 ┆ 7.177497    ┆ 29.857525 ┆ 0.026371 │\n",
       "│ 0.844719 ┆ 2135.648616 ┆ 39.282985 ┆ 0          ┆ 22.131268 ┆ -15.446129  ┆ 29.558203 ┆ 0.024677 │\n",
       "│ 0.935783 ┆ 1761.093708 ┆ 43.400548 ┆ 0          ┆ 23.711929 ┆ -25.952022  ┆ 28.854379 ┆ 0.020639 │\n",
       "│ 0.813516 ┆ 2109.378062 ┆ 40.055902 ┆ 0          ┆ 50.676327 ┆ -23.01264   ┆ 31.332929 ┆ 0.023267 │\n",
       "└──────────┴─────────────┴───────────┴────────────┴───────────┴─────────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos las primeras filas de la selección anterior.\n",
    "selection.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c6501",
   "metadata": {},
   "source": [
    "**<font color=\"mediumorchid\">Polars</font>** también nos provee de rutinas que nos permiten contar el número de valores distintos que puede tomar una variable de tipo categórica. Tales rutinas corresponden a `n_unique()` y `approx_unique()`.\n",
    "\n",
    "El método `n_unique()` nos permite contar el número de valores distintos ocurrentes en cualquier columna de un DataFrame, independiente de su tipo. Naturalmente, es una rutina pensada para la cuantía de valores únicos para variables categóricas u ordinales, aplicable sobretodo para DataFrames con una cantidad no demasiado grande (menor a unos cientos de miles) de filas.\n",
    "\n",
    "Por otro lado, el método `approx_unique()` nos permite hacer virtualmente lo mismo que con `n_unique()`. La diferencia es que `approx_unique()`, como su nombre lo sugiere, es una rutina que estima un valor aproximado de los valores únicos que toma una columna, lo que resulta muy útil en el contexto de DataFrames que almacenan millones de registros o más. Se trata pues de una rutina pensada para un contexto de *big data*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f1533d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuantía de valores únicos mediante n_unique().\n",
    "counts = df_flot.select(\n",
    "    [\n",
    "        pl.col(\"cond_relaves\").n_unique().alias(\"num_cond_relaves\"),\n",
    "        pl.col(\"perfil_niveles\").n_unique().alias(\"num_perfiles\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "85ed2f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 2)\n",
      "┌──────────────────┬──────────────┐\n",
      "│ num_cond_relaves ┆ num_perfiles │\n",
      "│ ---              ┆ ---          │\n",
      "│ u32              ┆ u32          │\n",
      "╞══════════════════╪══════════════╡\n",
      "│ 2                ┆ 3            │\n",
      "└──────────────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Mostramos el resultado anterior.\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9754a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuantía de valores únicos mediante approx_unique().\n",
    "counts = df_flot.select(\n",
    "    [\n",
    "        pl.col(\"cond_relaves\").approx_unique().alias(\"num_cond_relaves\"),\n",
    "        pl.col(\"perfil_niveles\").approx_unique().alias(\"num_perfiles\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "34d0b81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 2)\n",
      "┌──────────────────┬──────────────┐\n",
      "│ num_cond_relaves ┆ num_perfiles │\n",
      "│ ---              ┆ ---          │\n",
      "│ u32              ┆ u32          │\n",
      "╞══════════════════╪══════════════╡\n",
      "│ 2                ┆ 3            │\n",
      "└──────────────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Mostramos el resultado anterior.\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77603f5e",
   "metadata": {},
   "source": [
    "En una situación para la cual los DataFrames que manipulamos no tienen una enorme cantidad de registros, como ocurre en un contexto de *big data*, `n_unique()` y `approx_unique()` nos darán los mismos resultados, y con tiempos de ejecución similares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "30cdcede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 µs ± 6.22 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "112 µs ± 7.19 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit df_flot.select([pl.col(\"cond_relaves\").n_unique().alias(\"num_cond_relaves\"), pl.col(\"perfil_niveles\").n_unique().alias(\"num_perfiles\")])\n",
    "%timeit df_flot.select([pl.col(\"cond_relaves\").approx_unique().alias(\"num_cond_relaves\"), pl.col(\"perfil_niveles\").approx_unique().alias(\"num_perfiles\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040af515",
   "metadata": {},
   "source": [
    "Por lo tanto, es normal que en un contexto minero, simplemente nos limitemos a utilizar `n_unique()` para realizar cuantías como las anteriores.\n",
    "\n",
    "Otra rutina de cuantía muy común es `value_counts()`, y que nos permite contar el número de filas en un DataFrame para el cual el valor de una determinada columna se repite. También es útil para saber cómo se estratifica un dataset en función de ciertas variables categóricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2b94b785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>cuantia_instancias_por_perfil</th></tr><tr><td>struct[2]</td></tr></thead><tbody><tr><td>{&quot;Perfil no recuperativo&quot;,245}</td></tr><tr><td>{&quot;Perfil muy recuperativo&quot;,376}</td></tr><tr><td>{&quot;Perfil medianamente recuperativo&quot;,379}</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 1)\n",
       "┌───────────────────────────────────┐\n",
       "│ cuantia_instancias_por_perfil     │\n",
       "│ ---                               │\n",
       "│ struct[2]                         │\n",
       "╞═══════════════════════════════════╡\n",
       "│ {\"Perfil no recuperativo\",245}    │\n",
       "│ {\"Perfil muy recuperativo\",376}   │\n",
       "│ {\"Perfil medianamente recuperati… │\n",
       "└───────────────────────────────────┘"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generamos una cuantía de instancias por categoría.\n",
    "df_flot.select(\n",
    "    [\n",
    "        pl.col(\"perfil_niveles\").value_counts().alias(\"cuantia_instancias_por_perfil\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f94d7a2",
   "metadata": {},
   "source": [
    "La expresión `value_counts()` retorna un DataFrame con un mapeo de las cuantías requeridas (del tipo `Struct`), que se lee como `{valor: número de ocurrencias}`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
